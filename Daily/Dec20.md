# Generating Sequences with Recurrent Neural Networks 
by Alex Graves 

### RNN
standard RNN is unable to store information about past inputs for very long, and it generates based on only a few previous inputs. 

_____________________
 o  o o o o o o o 
 |  | | | | | | |
 h \h \ h \ h \ h 
 |  | | | | | | | 
 i  i i i i i i i 
______________________

h_t^n = H()
H is hidden layer function

### Interesting Explaination of Neural Network
RNNs are ‘fuzzy’ in the sense that they do not use exact templates from
the training data to make predictions, but rather—like other neural network use their internal representation to perform a high-dimensional interpolation between training examples.


### Thoughts 
These days I am making my modelling on voice. For thousands of times I want to give up for good. For thousands of times I want to quit AI because how can a person goes without a guiding star. 